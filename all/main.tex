\title{How to use YZ-HPC}
\author{
        %\large
        %\textsc{Vitaly Surazhsky}
        %    \qquad
        %\textsc{Joseph (Yossi) Gil}\thanks{Contact author}
        \mbox{}\\ %
        Department of Physics\\
        Shahjalal University of Science and Technology\\
        Sylhet - 3114, Bangladesh\\
        \mbox{}\\ %
        \normalsize
            \texttt{Support:}
        \textbar{}
            \texttt{yz-hpc}
        \normalsize
            \texttt{@sust.edu}
}
\date{}
\documentclass[11pt]{article}
%\documentclass{acmconf}

\usepackage[paper=a4paper,dvips,top=1.5cm,left=1.5cm,right=1.5cm,
    foot=1cm,bottom=1.5cm]{geometry}

\usepackage{times}
%\usepackage{graphicx}
\usepackage[fleqn]{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsopn}
\usepackage{xspace}
\usepackage{array}
\usepackage{epsfig}
\usepackage{listings}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=red,
}


\numberwithin{figure}{section}

\newcommand\CC{\Lang{\mbox{C++}}\xspace}
\newcommand\Lang[1]{\textsc{#1}}
\newcommand{\kw}[1]{\texttt{\textbf{#1}}}
\newcommand{\cd}[1]{\texttt{#1}}

\newcommand\Naturals{\ensuremath{\mathbb{N}}\xspace}
\newcommand\Integers{\ensuremath{\mathbb{Z}}\xspace}
\newcommand\Rationals{\ensuremath{\mathbb{Q}}\xspace}
\newcommand\Reals{\ensuremath{\mathbb{R}}\xspace}
\newcommand\Complex{\ensuremath{\mathbb{C}}\xspace}

\newcommand\norm[1]{\ensuremath{\lVert#1\rVert}}
\newcommand\abs[1]{\ensuremath{\lvert#1\rvert}}
\newcommand\ceil[1]{\ensuremath{\lceil#1\rceil}}
\newcommand\floor[1]{\ensuremath{\lfloor#1\rfloor}}
\newcommand\set[1]{\ensuremath{\{#1\}}}
\newcommand\angular[1]{\ensuremath{\langle#1\rangle}}

\newcommand\Norm[1]{\ensuremath{\left\lVert#1\right\rVert}}
\newcommand\Abs[1]{\ensuremath{\left\lvert#1\right\rvert}}
\newcommand\Ceil[1]{\ensuremath{\left\lceil#1\right\rceil}}
\newcommand\Floor[1]{\ensuremath{\left\lfloor#1\right\rfloor}}
\newcommand\Set[1]{\ensuremath{\left\{#1\right\}}}
\newcommand\Angular[1]{\ensuremath{\left\langle#1\right\rangle}}

\newcommand{\LOOM}{\ensuremath{\cal{LOOM}}\xspace}
\newcommand{\PolyTOIL}{\textbf{PolyTOIL}\xspace}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{definition}[theorem]{Definition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{fact}[theorem]{Fact}
\newtheorem{example}[theorem]{Example}

\newcommand\Cls[1]{\textsf{#1}}
\newcommand\Fig[1]{Figure~\ref{Figure:#1}}

\usepackage{labels} %
\usepackage{equation}
\usepackage{prog2tex}

\newenvironment{excerpt}{\begin{quote}\begin{minipage}\textwidth}{\end{minipage}\end{quote}}

\setcounter{topnumber}{0}
\setcounter{bottomnumber}{0}
\setcounter{totalnumber}{20}
\renewcommand{\textfraction}{0.01}

\begin{document}

\maketitle
 
\tableofcontents
% \begin{abstract}
% We present a programming technique for implementing
%     type safe covariance in \CC{}.
% In a sense, we implement most of Bruce's \emph{matching}
%     approach to the covariance dilemma in \CC.
% The appeal in our approach is that it relies on existing mechanisms,
%     specifically templates, and does not require any
%     modification to the existing language.
% The practical value of the technique was demonstrated
%     in its successful incorporation in a large software body.
% We identify the ingredients of a programming language
%     required for applying the technique, and discuss
%     extensions to other languages.
% \end{abstract}

\section{Getting started with the HPC}

The configuration of YZ-HPC is described below:

\begin{itemize}
    \item Hardware
        \begin{itemize}
            \item Compute Node: 05
                \begin{itemize}
                    \item CPU: Intel Xeon 4-core 2.1 GHz
                    \item RAM: 8 GB 800 MHz
                \end{itemize}
            \item Compute Node: 16
                \begin{itemize}
                    \item CPU: Intel Core 2 Duo 2.6 GHz
                    \item RAM: 4 GB 800 MHz
                \end{itemize}
            \item Total Core: 52 Compute Core
            \item Total RAM: 104 GB
        \end{itemize}
    \item Software
        \begin{itemize}
            \item OS: \href{https://www.teliscos.org}{Telisc OS}
            \item Module Environment: \href{https://lmod.readthedocs.io/en/latest/} {lmod}
            \item Task/Job Management and Schedular: \href{https://slurm.schedmd.com} {SLURM}
        \end{itemize}
    \item Computation Software: OpenMPI (Version 2.1.3 and 3.0.0)
    \item Molecuar Dynamics: LAMMPS
    \item Computational Chemistry: Gaussian (g09)
\end{itemize}

\subsection{How do I get access to the HPC}
Fill out the appropriate tab of the HPC Access Request Form. Access is
typically granted within few business days. Before requesting access, a minimum experience with the followings are expected:

\begin{itemize}
    \item How to work on Linux Terminal
    \item How to write within Linux Terminal (with vim/nano)
    \item Basics of OpenMPI
    \item File transfer tools (rsync, FileZilla, WinSCP etc.)
\end{itemize}

\subsection{YZ-HPC Documentation}
All the documentation are described brifely at \href{http://10.100.11.71} {http://yz-hpc.phy.edu}. An HPC Access Request Form or Registration form is available for registering into YZ-HPC. A username with password will be sent to the user after the registration completion. Those username and password is very important for login.

NOTE: DO NOT CHANGE THE PASSWORD.

\subsection{How do I login in the system}
Only SSH access is available to login in the system. Any SSH client from
various Operating System can be used. Additionally a web browser can be used to
get login (firefox, google-chrome, Internet Explorer and Microsft edges were
tested).

\subsubsection{From web browser}

\begin{description}
    \item[url] \href{http://10.100.11.71}{http://yz-hpc.phy.edu}
    \item[CLI] Click \textbf{Go to Command Line Interface}
    \item[Permission] Accept the secure access
    \item[localhost] 10.100.11.71
    \item[Port] 22
    \item[username] USERNAME
    \item[password] PASSWORD
\end{description}

A login shell will be available if everything goes fine.

\subsection{How do I run my jobs on the HPC}
See the documents below sections for basic examples of several types of jobs on
the HPC system.

\begin{itemize}
    \item HPC Sample Job: OpenMPI
    \item HPC Sample Job: LAMMPS
    \item HPC Sample Job: Gaussian
\end{itemize}

\subsection{How many jobs can I run?}
\subsection{Why are some of my jobs stuck in the queue?}

\section{How do I use TextEditor}
By default vim and nano text editor is provided in the YZ-HPC because of their
simplicity.

\subsection{Documentation on TextEditor}
\begin{itemize}
    \item Vim (An online tutorial is available at \href{http://www.openvim.com}{here})
    \item Nano (A simple tutorial is available at \href{https://staffwww.fullcoll.edu/sedwards/Nano/IntroToNano.html}{here}) 
\end{itemize}

\section{How do I transfer file into/from YZ-HPC}
Any standard SSH tool can be used to transfer files between HPC and client
computer. The rsync, WinSCP are Filezilla very useful tools.

\subsection{Documentation on File Transfer}

\section{HPC Sample Job: OpenMPI}
\subsection{Overview}
This document shows a very simple "Hello, World!" type program using OpenMPI
libraries, adapted from MPI Tutorial: MPI Hello World.

mpi\_hw.c

\begin{lstlisting}[frame=single]
#include <mpi.h>
#include <stdio.h>
 
int main(int argc, char** argv) {
  MPI_Init(NULL, NULL);
  int world_size;
  MPI_Comm_size(MPI_COMM_WORLD, &world_size);
  int world_rank;
  MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);
  char processor_name[MPI_MAX_PROCESSOR_NAME];
  int name_len;
  MPI_Get_processor_name(processor_name, &name_len);
  printf("Hello world from processor %s, rank %d"
     " out of %d processors\n",
     processor_name, world_rank, world_size);
  MPI_Finalize();
}
\end{lstlisting}

\subsection{Loading OpenMPI}
There are two different version of openMPI available for computing. They are
version 2.1.3 and 3.0.0. Use module tools to load the appropriate version of
the MPI.

\begin{lstlisting}[frame=single]
$ module load openMPI
\end{lstlisting}

\subsection{Compiling}
On the login node or a compute node, the source can be compiled after the
module loaded as:

\begin{lstlisting}[frame=single]
$ mpicc -o mpi_hw mpi_hw.c
\end{lstlisting}

\subsection{Running the compiled code}
No one should run an MPI code directly in the HPC. Use batch script to submit
as a job on the system.

\subsection{Running MPI in batch}
Make a Slurm job script named mpi\_hw.sh with the following contents.

mpi\_hw.sh

\begin{lstlisting}[frame=single]
#!/bin/bash
#SBATCH --node=2
#SBATCH --job-name=mpi_hw
#SBATCH --output=mpi_hw

module load openMPI

mpicc -o mpi_hw mpi_hw.c

mpirun ./mpi_hw
\end{lstlisting}


\subsection{Submitting job in Queue}

\begin{lstlisting}[frame=single]
$ sbatch mpi_hw.sh
\end{lstlisting}

\subsection{Useful Links for openMPI}

\begin{itemize}
    \item \href{https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwiC3oqOga_aAhXCvY8KHXJYCqwQFggnMAA&url=http%3A%2F%2Fmpitutorial.com%2Ftutorials%2F&usg=AOvVaw3gcXG-8XhYsVPu5egCZ2EP} {MPI tutorial}

\item \href{http://mpitutorial.com/tutorials/mpi-hello-world/}{MPI tutorial}
\end{itemize}
\end{document}
